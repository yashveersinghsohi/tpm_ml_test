# References:
# - https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest
# - https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis

# Importing Relevant Packages
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer
)
from scipy.special import softmax


# TODO - DEFINE YOUR FEATURE EXTRACTOR HERE
def get_model_scores(model_id: str, text: str) -> dict:
    """
        This function takes in the model identifier from huggingface,
        and returns the score from that model on the input text.

    ARGS:
        :model_id (str): A string identifier which is used to retrieve the pretrained model from huggingface
        :text (str): The input string (in this case, a single chat!) that needs to be scored by the model

    RETURNS:
        :(dict): The output dictionary is of the format
                    {'positive': <probability_of_positive_sentiment>,
                     'negative': <probability_of_negative_sentiment>,
                     'neutral': <probability_of_neutral_sentiment>}
                 Here, each of these probabilities are between 0, and 1; and all the 3 numbers sum up to 1.0
    """
    # Initializing Relevant Model and Tokenizer from Huggingface
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForSequenceClassification.from_pretrained(model_id)

    # Tokenizing Input text
    tokens = tokenizer(text, return_tensors='pt')
    # Retrieving Model Output
    output = model(**tokens)
    # Extracting Scores from Output Tensors
    scores = output[0][0].detach().numpy()
    # Converting Scores into Probabilities
    scores = softmax(scores)

    # Returning Scores Dictionary
    return {'positive': scores[2], 'negative': scores[0], 'neutral': scores[1]}


def get_sentiment(text: str) -> dict:
    """
        In this function we retrieve the scores generated by 2 sentiment analysis models,
        and then stack them together (take their average) to get more robust sentiment
        scores for the input text.

    ARGS:
        :text (str): The input string (in this case, a single chat!) that needs to be scored by the 2 models

    RETURNS:
        :(dict): The output dictionary is of the format
                    {'positive': <probability_of_positive_sentiment>,
                     'negative': <probability_of_negative_sentiment>,
                     'neutral': <probability_of_neutral_sentiment>}
                 Here, each of these probabilities are between 0, and 1; and all the 3 numbers sum up to 1.0
    """
    # Getting scores for input text using this model:
    # https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest
    twitter_model_scores = get_model_scores(model_id=f"cardiffnlp/twitter-roberta-base-sentiment-latest", text=text)
    # Getting scores for input text using this model:
    # https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis
    pysentimiento_model_scores = get_model_scores(model_id=f"pysentimiento/robertuito-sentiment-analysis", text=text)

    # Printing model scores (For debugging code runs)
    print(f"Twitter Model Scores for '{text}': {twitter_model_scores}")
    print(f"Pysentimiento Model Scores for '{text}': {pysentimiento_model_scores}")

    # The probability scores for each sentiment type (positive, negative, neutral)
    # are averaged from the 2 models in this dictionary
    stacked_scores = [
        (twitter_model_scores['positive'] + pysentimiento_model_scores['positive']) / 2.0,
        (twitter_model_scores['negative'] + pysentimiento_model_scores['negative']) / 2.0,
        (twitter_model_scores['neutral'] + pysentimiento_model_scores['neutral']) / 2.0
    ]
    # To ensure that the resulting scores sum up to 1, we normalize the scores calculated above.
    # Note that this step is redundant in the current implementation,
    # as the scores are stacked using simple arithmetic means. In future, if the stacking is done non-evenly,
    # then this step would make more sense.
    total_score = sum(stacked_scores)
    stacked_prob_scores = [score / total_score for score in stacked_scores]

    # Returning Final Scores Dictionary
    return {'positive': stacked_prob_scores[0], 'negative': stacked_prob_scores[1], 'neutral': stacked_prob_scores[2]}
